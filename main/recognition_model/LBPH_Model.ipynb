{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecbf6d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maniklaldas/Desktop/foreheadData/test/1_P2_S1_1.jpg\n",
      "Person Identified = 1; Confidence = 100.0\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/12_P1_S2_3.jpg\n",
      "Person Identified = 12; Confidence = 67.78557392323239\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/1_P2_S1_3.jpg\n",
      "Person Identified = 1; Confidence = 66.40025222996667\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/25_P1_S2_3.jpg\n",
      "Person Identified = 5; Confidence = 51.38850382048335\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/4_P2_S1_2.jpg\n",
      "Person Identified = 6; Confidence = 51.00271134041872\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/4_P2_S1_3.jpg\n",
      "Person Identified = 25; Confidence = 57.42626176958992\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/28_P2_S1_3.jpg\n",
      "Person Identified = 28; Confidence = 74.904626215077\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/12_P1_S1_2.jpg\n",
      "Person Identified = 12; Confidence = 70.04170665361279\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/3_P1_S1_3.jpg\n",
      "Person Identified = 3; Confidence = 64.12379397102188\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/2_P2_S1_2.jpg\n",
      "Person Identified = 2; Confidence = 82.56701442265911\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/18_P1_S2_3.jpg\n",
      "Person Identified = 7; Confidence = 55.5430560748031\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/18_P1_S2_2.jpg\n",
      "Person Identified = 7; Confidence = 53.36834676515363\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/18_P2_S1_1.jpg\n",
      "Person Identified = 18; Confidence = 57.09874879550054\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/6_P2_S2_1.jpg\n",
      "Person Identified = 5; Confidence = 75.24629417447738\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/24_P1_S1_3.jpg\n",
      "Person Identified = 24; Confidence = 33.02369871811861\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/3_P2_S1_2.jpg\n",
      "Person Identified = 3; Confidence = 75.77045597553615\n",
      "\n",
      "/Users/maniklaldas/Desktop/foreheadData/test/1_P1_S2_2.jpg\n",
      "Person Identified = 1; Confidence = 70.1349180227837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "from google.colab.patches import cv2_imshow\n",
    "from PIL import Image\n",
    "\n",
    "IMAGE_DIRECTORY = '/Users/maniklaldas/Desktop/foreheadData'\n",
    "TRAINING_IMAGES = IMAGE_DIRECTORY + '/train'\n",
    "TEST_IMAGES = IMAGE_DIRECTORY + '/test'\n",
    "\n",
    "USERNAMES = [str(i) for i in range(1, 29)]\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for username in USERNAMES:\n",
    "    user_images = TRAINING_IMAGES + '/' + username\n",
    "    \n",
    "    for file in os.listdir(user_images):\n",
    "        image_path = user_images + '/' + file\n",
    "        image = cv.imread(image_path)\n",
    "        \n",
    "        grayscale_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "        features.append(grayscale_image)\n",
    "        labels.append(int(username))\n",
    "        \n",
    "feature_vector = np.array(features, dtype='object')\n",
    "label_vector = np.array(labels)\n",
    "\n",
    "face_recognition_model = cv.face.LBPHFaceRecognizer_create()\n",
    "face_recognition_model.train(feature_vector, label_vector)\n",
    "\n",
    "\n",
    "face_recognition_model.save('face_recognition.yml')\n",
    "np.save('feature_vector.npy', feature_vector)\n",
    "np.save('label_vector.npy', label_vector)\n",
    "\n",
    "#feature_vector = np.load('feature_vector.npy', allow_pickle=True)\n",
    "#label_vector = np.load('label_vector.npy')\n",
    "face_recognition_model = cv.face.LBPHFaceRecognizer_create()\n",
    "face_recognition_model.read('face_recognition.yml')\n",
    "\n",
    "for file in os.listdir(TEST_IMAGES):\n",
    "    image_path = TEST_IMAGES + '/' + file\n",
    "    image = cv.imread(image_path)\n",
    "    \n",
    "    grayscale_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    label, confidence_complement = face_recognition_model.predict(grayscale_image)\n",
    "    print(image_path)\n",
    "    print(\"Person Identified = \" + str(label) + \"; Confidence = \" + str(100 - confidence_complement))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2bba21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
